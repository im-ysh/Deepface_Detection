{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofv2247p7SSL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a2df26a-837a-46eb-caec-6f34424330cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/deepfake_detection\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baAK2pgV-SFS",
        "outputId": "531013ab-5a1d-470f-9f71-9773e4465e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/deepfake_detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch numpy\n"
      ],
      "metadata": {
        "id": "ANe5hLowANFn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6800ad47-4c06-46d6-af3f-9112ef3d1021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "v1 = np.load(\"/content/drive/MyDrive/deepfake_detection/data/all_embeddings.npy\")\n",
        "v2 = np.load(\"/content/drive/MyDrive/deepfake_detection/data/v2_embeddings.npy\")\n",
        "combined = np.concatenate((v1, v2), axis=1)\n",
        "np.save(\"/content/drive/MyDrive/deepfake_detection/data/combined_embeddings.npy\", combined)\n",
        "\n",
        "# Save labels (use v2 or all)\n",
        "labels = np.load(\"/content/drive/MyDrive/deepfake_detection/data/v2_labels.npy\")\n",
        "np.save(\"/content/drive/MyDrive/deepfake_detection/data/combined_labels.npy\", labels)\n"
      ],
      "metadata": {
        "id": "khgMZwO6Ci3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/deepfake_detection/sho_simple.py\n",
        "import numpy as np\n",
        "\n",
        "def SHO(obj_func, lb, ub, num_hyenas=50, max_iter=100):\n",
        "    dim = len(lb)\n",
        "    hyenas = np.random.uniform(lb, ub, (num_hyenas, dim))\n",
        "    fitness = np.zeros(num_hyenas)\n",
        "\n",
        "    for t in range(max_iter):\n",
        "        for i in range(num_hyenas):\n",
        "            fitness[i] = obj_func(hyenas[i, :])\n",
        "\n",
        "        best_hyena_idx = np.argmin(fitness)\n",
        "        best_hyena = hyenas[best_hyena_idx, :]\n",
        "\n",
        "        for i in range(num_hyenas):\n",
        "            if i == best_hyena_idx:\n",
        "                continue\n",
        "\n",
        "            dist = np.linalg.norm(hyenas[i, :] - best_hyena)\n",
        "            if fitness[i] < fitness[best_hyena_idx]:\n",
        "                a = 2.0 - 2.0 * t / max_iter\n",
        "                b = np.random.uniform(0, 1)\n",
        "                hyenas[i, :] += a * np.exp(-b * dist) * (hyenas[i, :] - best_hyena)\n",
        "            else:\n",
        "                a = 2.0 * t / max_iter\n",
        "                b = np.random.uniform(0, 1)\n",
        "                hyenas[i, :] += a * np.exp(-b * dist) * (hyenas[i, :] - best_hyena)\n",
        "\n",
        "            hyenas[i, :] = np.clip(hyenas[i, :], lb, ub)\n",
        "\n",
        "    best_idx = np.argmin(fitness)\n",
        "    return hyenas[best_idx, :], fitness[best_idx]\n"
      ],
      "metadata": {
        "id": "-ce9L4AAbKbI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "559c215f-d538-4c9f-d856-515f9f2f1305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/deepfake_detection/sho_simple.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/deepfake_detection/train_task2_enhanced_sho.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwGfyoA_2aLb",
        "outputId": "3d939d79-5543-4d92-b336-b1f1794fb84e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/deepfake_detection/train_task2_enhanced_sho.py\", line 111, in <module>\n",
            "    best_solution, best_fitness = SHO(fitness, lb, ub, num_hyenas=10, max_iter=60, verbose=True, callback=sho_callback)\n",
            "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: SHO() got an unexpected keyword argument 'verbose'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/deepfake_detection/task3_updated.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x1zZ9lz5Xjx",
        "outputId": "f6dfde72-262f-4bde-cd99-a83e73d52e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model loaded. Starting evaluation on test set...\n",
            "\n",
            "🎯 Test Set Evaluation Results:\n",
            "Accuracy : 0.5149\n",
            "Precision: 0.5573\n",
            "Recall   : 0.4280\n",
            "F1 Score : 0.4842\n",
            "📁 Video-level predictions saved to task3_video_results_enhanced.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(os.listdir(\"/content/drive/MyDrive/deepfake_detection\"))\n"
      ],
      "metadata": {
        "id": "zQkrRy31RQYr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7872f25c-ec58-487c-fb20-071e9314b5b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['data', 'models', '__pycache__', '.ipynb_checkpoints', 'train_task2_enhanced_sho.py', 'mem_task2_bilstm_sho_enhanced.pth', 'task3_video_results_enhanced.csv', 'task3_updated.py', 'train_task2_adam.py', 'task3_adam.py', 'sho_simple.py', 'mem_task2_bilstm_adam.pth', 'task3_video_results_adam.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/deepfake_detection/train_task2_adam.py\n"
      ],
      "metadata": {
        "id": "6VJadQ01F4IR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73461b0c-32b2-49fb-e2f4-aae82e3fc4f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.6103\n",
            "Epoch 2/10, Loss: 0.2600\n",
            "Epoch 3/10, Loss: 0.1067\n",
            "Epoch 4/10, Loss: 0.0525\n",
            "Epoch 5/10, Loss: 0.0349\n",
            "Epoch 6/10, Loss: 0.0103\n",
            "Epoch 7/10, Loss: 0.0275\n",
            "Epoch 8/10, Loss: 0.0484\n",
            "Epoch 9/10, Loss: 0.0086\n",
            "Epoch 10/10, Loss: 0.0215\n",
            "✅ Model trained using Adam and saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/deepfake_detection/task3_adam.py\n"
      ],
      "metadata": {
        "id": "Y1LAeVnVGEK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16772c5f-ae71-4127-9b0e-6f6c964c6a46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Adam-trained model loaded. Starting evaluation on test set...\n",
            "\n",
            "🎯 Adam Model Evaluation Results:\n",
            "Accuracy : 0.9809\n",
            "Precision: 0.9725\n",
            "Recall   : 0.9920\n",
            "F1 Score : 0.9822\n",
            "📁 Adam video-level predictions saved to task3_video_results_adam.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vTwTX4XmPMiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Class Distribution of Labels\n",
        "import numpy as np\n",
        "labels = np.load(\"/content/drive/MyDrive/deepfake_detection/data/combined_labels.npy\")\n",
        "unique, counts = np.unique(labels, return_counts=True)\n",
        "print(dict(zip(unique, counts)))\n"
      ],
      "metadata": {
        "id": "anmWtg38GQNJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff18df65-3437-46f8-e13d-ee3ea42d1db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{np.int64(0): np.int64(8796), np.int64(1): np.int64(10000)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of Test Labels\n",
        "test_labels = np.load(\"/content/drive/MyDrive/deepfake_detection/data/test_labels.npy\")\n",
        "unique, counts = np.unique(test_labels, return_counts=True)\n",
        "print(\"Test set label distribution:\", dict(zip(unique, counts)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULES9M09P8Hg",
        "outputId": "4b42a9b4-e0f6-4655-de51-5cfe14d7b2c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set label distribution: {np.int64(0): np.int64(220), np.int64(1): np.int64(250)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Predictions\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/deepfake_detection/task3_video_results_adam.csv\")\n",
        "print(df['Predicted_Label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44_XUP4xQCix",
        "outputId": "c654b08e-6d66-4e8e-c4dd-a5532a31cb0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted_Label\n",
            "1    255\n",
            "0    215\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/deepfake_detection/\n"
      ],
      "metadata": {
        "id": "XJld5qNT9Zqa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31c16740-81dc-4c4f-a078-0f3537f0c63e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\t\t\t\t   task3_adam.py\n",
            "mem_task2_bilstm_adam.pth\t   task3_updated.py\n",
            "mem_task2_bilstm_sho_enhanced.pth  task3_video_results_adam.csv\n",
            "models\t\t\t\t   task3_video_results_enhanced.csv\n",
            "__pycache__\t\t\t   train_task2_adam.py\n",
            "sho_simple.py\t\t\t   train_task2_enhanced_sho.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all dependencies in one cell\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Add the parent directory of 'models' to the system path\n",
        "# Assuming 'models' is directly inside '/content/drive/MyDrive/deepfake_detection/'\n",
        "import sys\n",
        "import os\n",
        "models_dir = \"/content/drive/MyDrive/deepfake_detection/\"\n",
        "if models_dir not in sys.path:\n",
        "    sys.path.append(models_dir)\n",
        "\n",
        "# Now, the import should work if the 'models' directory and 'mem_task2_model.py' exist within models_dir\n",
        "from models.mem_task2_model import BiLSTMAttentionModel\n",
        "\n",
        "\n",
        "# 1. Load and preprocess data (same as train_task2_adam.py)\n",
        "all_features = np.load(\"/content/drive/MyDrive/deepfake_detection/data/combined_embeddings.npy\")\n",
        "all_labels = np.load(\"/content/drive/MyDrive/deepfake_detection/data/combined_labels.npy\")\n",
        "total_frames = (len(all_features) // 8) * 8\n",
        "train_features = all_features[:total_frames].reshape(-1, 8, 1024)\n",
        "train_labels = all_labels[:total_frames].reshape(-1, 8)\n",
        "majority_labels = np.array([np.bincount(seq).argmax() for seq in train_labels])\n",
        "\n",
        "# 2. Recreate Dataset/Dataloader (same as original)\n",
        "class FeatureSequenceDataset(Dataset):\n",
        "    def __init__(self, features, labels, sequence_length=8):\n",
        "        self.features = features.reshape(-1, 1024)\n",
        "        # The labels should also be shaped to match the number of sequences, not the individual frames\n",
        "        self.labels = labels\n",
        "        self.sequence_length = sequence_length\n",
        "        self.num_sequences = len(self.features) // sequence_length\n",
        "\n",
        "    def __len__(self):\n",
        "        # Added __len__ method to return the number of sequences\n",
        "        return self.num_sequences\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start = idx * self.sequence_length\n",
        "        end = start + self.sequence_length\n",
        "        sequence = self.features[start:end]\n",
        "        # Get the single majority label for the sequence\n",
        "        label = self.labels[idx]\n",
        "        return torch.tensor(sequence, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "# Pass the majority labels (one per sequence) to the dataset\n",
        "train_dataset = FeatureSequenceDataset(train_features, majority_labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# 3. Load trained model (same as task3_adam.py)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BiLSTMAttentionModel(input_dim=1024, num_classes=2).to(device)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/deepfake_detection/mem_task2_bilstm_adam.pth\", map_location=device))\n",
        "\n",
        "# 4. Calculate training accuracy\n",
        "model.eval()\n",
        "correct = total = 0\n",
        "with torch.no_grad():\n",
        "    for sequences, labels in train_loader:\n",
        "        sequences, labels = sequences.to(device), labels.to(device)\n",
        "        outputs = model(sequences)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Training Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAvsbaIhVpef",
        "outputId": "fc3e9feb-f90a-4d0a-8f9d-673a3253f25c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 99.02%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JQ_t4nXMX0TU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}